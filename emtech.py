# -*- coding: utf-8 -*-
"""MIDTERMS EMTECH

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EV2KQXeze5HcIYdtBocGUHN34ooBHYA8
"""


import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.preprocessing import image
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
import zipfile
import os

from google.colab import files
uploaded = files.upload()

for file_name in uploaded.keys():
    with zipfile.ZipFile(file_name, 'r') as zip_ref:
        zip_ref.extractall('/content/dataset')

print("Dataset unzipped successfully to /content/dataset")

batch_size = 50
img_height, img_width = 64, 64

dataset_path = '/content/dataset'
dataset = tf.keras.preprocessing.image_dataset_from_directory(
    dataset_path,
    labels="inferred",
    label_mode="int",
    batch_size=batch_size,
    image_size=(img_height, img_width),
    shuffle=True,
    seed=42
)

train_ds = dataset.take(int(len(dataset) * 0.8))
val_ds = dataset.skip(int(len(dataset) * 0.8))
class_names = dataset.class_names
print("Classes:", class_names)

import numpy as np

counts = []
for i in range(len(class_names)):
    count = 0
    for images, labels in dataset:
        count += np.sum(labels.numpy() == i)
    counts.append(count)

sns.barplot(x=class_names, y=counts)
plt.title("Class Distribution of Images")
plt.show()

normalization_layer = tf.keras.layers.Rescaling(1./255)

model = Sequential([
    Flatten(input_shape=(img_height, img_width, 3)),
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dense(len(class_names), activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

history = model.fit(
    train_ds.map(lambda x, y: (normalization_layer(x), y)),
    validation_data=val_ds.map(lambda x, y: (normalization_layer(x), y)),
    epochs=20
)
print("Baseline model trained successfully.")

plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

val_loss, val_accuracy = model.evaluate(val_ds.map(lambda x, y: (normalization_layer(x), y)))
print("Validation Accuracy:", val_accuracy)

improved_model = Sequential([
    Flatten(input_shape=(img_height, img_width, 3)),
    Dense(256, activation='relu'),
    Dropout(0.3),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dense(len(class_names), activation='softmax')
])

improved_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])


history_improved = improved_model.fit(
    train_ds.map(lambda x, y: (normalization_layer(x), y)),
    validation_data=val_ds.map(lambda x, y: (normalization_layer(x), y)),
    epochs=30
)

print("Improved model trained successfully.")

save_path = "/content/best_mlp_model.keras"
improved_model.save(save_path)
print(f"Model saved at {save_path}")

best_model = tf.keras.models.load_model("/content/best_mlp_model.keras")

best_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

uploaded = files.upload()


best_model = tf.keras.models.load_model("/content/best_mlp_model.keras")

for sample_image_path in uploaded.keys():

    img = image.load_img(sample_image_path, target_size=(img_height, img_width))
    img_array = image.img_to_array(img) / 255.0
    img_array = tf.expand_dims(img_array, 0)


    prediction = best_model.predict(img_array)
    predicted_class = class_names[np.argmax(prediction)]
    print(f"Predicted Class for {sample_image_path}: {predicted_class}")
